{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84eaba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc6300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tedlasai/miniconda3/envs/p312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#CONDA ENVIRONEMNT P312\n",
    "\n",
    "import os\n",
    "#add to system path\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from metrics_helpers import read_image, pre_hdr_p3, align_hdr_pred_to_gt, psnr, vsi, piqe, lpips, hdr_vdp3, pu, reinhard_tonemap\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from metrics_helpers import initialize_fid, initialize_fvd\n",
    "from metrics_helpers import compute_fid, fid_update, compute_fvd, fvd_update\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53593b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading videomae model ...\n",
      "Loading videomae model ...\n",
      "PU-PSNR: 23.015549\n",
      "PU-VSI: 0.9831276225897186\n",
      "PIQE Score: 22.94376\n",
      "LPIPS Score: 0.1962708830833435\n",
      "PU-PSNR: 23.053814\n",
      "PU-VSI: 0.983399357102978\n",
      "PIQE Score: 21.128637\n",
      "LPIPS Score: 0.1977754533290863\n",
      "PU-PSNR: 23.010555\n",
      "PU-VSI: 0.9832050596010347\n",
      "PIQE Score: 24.785967\n",
      "LPIPS Score: 0.2003951370716095\n",
      "PU-PSNR: 23.04801\n",
      "PU-VSI: 0.983188014986581\n",
      "PIQE Score: 23.179743\n",
      "LPIPS Score: 0.20237594842910767\n",
      "PU-PSNR: 21.899685\n",
      "PU-VSI: 0.9880647102286683\n",
      "PIQE Score: 45.35233\n",
      "LPIPS Score: 0.09521180391311646\n",
      "PU-PSNR: 21.835318\n",
      "PU-VSI: 0.9878661738812461\n",
      "PIQE Score: 41.74559\n",
      "LPIPS Score: 0.08944909274578094\n",
      "PU-PSNR: 21.783247\n",
      "PU-VSI: 0.9877924892629196\n",
      "PIQE Score: 46.167854\n",
      "LPIPS Score: 0.08692405372858047\n",
      "PU-PSNR: 21.78904\n",
      "PU-VSI: 0.9878509877094722\n",
      "PIQE Score: 45.83061\n",
      "LPIPS Score: 0.08745228499174118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tedlasai/miniconda3/envs/p312/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric FrechetInceptionDistance was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "More than one sample is required for both the real and fake distributed to compute FID",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     91\u001b[39m     fvd_update(reinhard_preds, reinhard_gts, reinhard_fvd_metric)\n\u001b[32m     92\u001b[39m     fvd_update(pu_preds, pu_gts, pu_fvd_metric)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mR-FID Score:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mcompute_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreinhard_fid_metric\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mR-FVD Score:\u001b[39m\u001b[33m\"\u001b[39m, compute_fvd(reinhard_fvd_metric))\n\u001b[32m     96\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPU-FID Score:\u001b[39m\u001b[33m\"\u001b[39m, compute_fid(pu_fid_metric))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/riemann_share_2/home/tedlasai/hdrvideo/metrics/metrics_helpers.py:114\u001b[39m, in \u001b[36mcompute_fid\u001b[39m\u001b[34m(fid_metric)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_fid\u001b[39m(fid_metric):\n\u001b[32m    113\u001b[39m     \u001b[38;5;66;03m# Compute FID score from the accumulated features\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mfid_metric\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/p312/lib/python3.12/site-packages/torchmetrics/metric.py:633\u001b[39m, in \u001b[36mMetric._wrap_compute.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;66;03m# compute relies on the sync context manager to gather the states across processes and apply reduction\u001b[39;00m\n\u001b[32m    626\u001b[39m \u001b[38;5;66;03m# if synchronization happened, the current rank accumulated states will be restored to keep\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[38;5;66;03m# accumulation going if ``should_unsync=True``,\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sync_context(\n\u001b[32m    629\u001b[39m     dist_sync_fn=\u001b[38;5;28mself\u001b[39m.dist_sync_fn,\n\u001b[32m    630\u001b[39m     should_sync=\u001b[38;5;28mself\u001b[39m._to_sync,\n\u001b[32m    631\u001b[39m     should_unsync=\u001b[38;5;28mself\u001b[39m._should_unsync,\n\u001b[32m    632\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     value = _squeeze_if_scalar(\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    634\u001b[39m     \u001b[38;5;66;03m# clone tensor to avoid in-place operations after compute, altering already computed results\u001b[39;00m\n\u001b[32m    635\u001b[39m     value = apply_to_collection(value, Tensor, \u001b[38;5;28;01mlambda\u001b[39;00m x: x.clone())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/p312/lib/python3.12/site-packages/torchmetrics/image/fid.py:382\u001b[39m, in \u001b[36mFrechetInceptionDistance.compute\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calculate FID score based on accumulated extracted features from the two distributions.\"\"\"\u001b[39;00m\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.real_features_num_samples < \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fake_features_num_samples < \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMore than one sample is required for both the real and fake distributed to compute FID\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    383\u001b[39m mean_real = (\u001b[38;5;28mself\u001b[39m.real_features_sum / \u001b[38;5;28mself\u001b[39m.real_features_num_samples).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m    384\u001b[39m mean_fake = (\u001b[38;5;28mself\u001b[39m.fake_features_sum / \u001b[38;5;28mself\u001b[39m.fake_features_num_samples).unsqueeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: More than one sample is required for both the real and fake distributed to compute FID"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_dir = \"/home/tedlasai/hdrvideo/evaluations/ours_stuttgart/under/\"\n",
    "gt_dir =  \"/home/tedlasai/hdrvideo/evaluations/stuttgart/hdr/\"\n",
    "# video_paths = sorted(os.listdir(pred_dir))\n",
    "video_paths = [\"bistro_01\",\"bistro_02\"]\n",
    "\n",
    "reinhard_fvd_metric = initialize_fvd()\n",
    "reinhard_fid_metric = initialize_fid()\n",
    "\n",
    "pu_fvd_metric = initialize_fvd()\n",
    "pu_fid_metric = initialize_fid()\n",
    "\n",
    "psnr_scores = []\n",
    "vsi_scores = []\n",
    "piqe_scores = []\n",
    "lpips_scores = []\n",
    "\n",
    "for video_path in video_paths:\n",
    "    pred_video_dir = os.path.join(pred_dir, video_path)\n",
    "    gt_video_dir = os.path.join(gt_dir, video_path)\n",
    "    im_paths = sorted(os.listdir(pred_video_dir))[:4]\n",
    "\n",
    "    reinhard_preds = []\n",
    "    reinhard_gts = []\n",
    "    pu_preds = []\n",
    "    pu_gts = []\n",
    "    for im_path in im_paths:\n",
    "        pred_im_path = os.path.join(pred_video_dir, im_path)\n",
    "        gt_im_path = os.path.join(gt_video_dir, im_path)\n",
    "        cv2_hdr_pred = read_image(pred_im_path)\n",
    "        cv2_hdr_gt = read_image(gt_im_path)\n",
    "        cv2_hdr_gt = pre_hdr_p3(cv2_hdr_gt)\n",
    "        cv2_hdr_pred,cv2_hdr_gt,_ = align_hdr_pred_to_gt(cv2_hdr_pred, cv2_hdr_gt)\n",
    "\n",
    "        # import matplotlib.pyplot as plt\n",
    "\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "        # axes[0].hist(cv2_hdr_gt.flatten(), bins=100, range=(0, 1000))\n",
    "        # axes[0].set_title(\"GT\")\n",
    "\n",
    "        # axes[1].hist(cv2_hdr_pred.flatten(), bins=100, range=(0, 1000))\n",
    "        # axes[1].set_title(\"Pred\")\n",
    "\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "        # axes[0].imshow(cv2_hdr_gt / np.max(cv2_hdr_gt))\n",
    "        # axes[0].set_title(\"GT\")\n",
    "        # axes[0].axis(\"off\")\n",
    "\n",
    "        # axes[1].imshow(cv2_hdr_pred / np.max(cv2_hdr_pred))\n",
    "        # axes[1].set_title(\"Pred\")\n",
    "        # axes[1].axis(\"off\")\n",
    "\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        jod = hdr_vdp3(cv2_hdr_pred, cv2_hdr_gt)\n",
    "\n",
    "        pu_pred, pu_gt = pu(cv2_hdr_pred), pu(cv2_hdr_gt)\n",
    "        pu_preds.append(pu_pred/np.max(pu_gt))\n",
    "        pu_gts.append(pu_gt/np.max(pu_gt))\n",
    "\n",
    "        reinhard_pred, reinhard_gt = reinhard_tonemap(cv2_hdr_pred), reinhard_tonemap(cv2_hdr_gt)\n",
    "        reinhard_preds.append(reinhard_pred)\n",
    "        reinhard_gts.append(reinhard_gt)\n",
    "\n",
    "\n",
    "        pu_psnr = psnr(pu_pred, pu_gt)\n",
    "        psnr_scores.append(pu_psnr)\n",
    "        print(\"PU-PSNR:\", pu_psnr)\n",
    "\n",
    "        pu_vsi = vsi(pu_pred, pu_gt)\n",
    "        vsi_scores.append(pu_vsi)   \n",
    "        print(\"PU-VSI:\", pu_vsi)\n",
    "\n",
    "        pu_piqe = piqe(pu_pred)\n",
    "        piqe_scores.append(pu_piqe)\n",
    "        print(\"PIQE Score:\", pu_piqe)\n",
    "\n",
    "        pu_lpips = lpips(reinhard_pred, reinhard_gt)\n",
    "        lpips_scores.append(pu_lpips)\n",
    "        print(\"LPIPS Score:\", pu_lpips)\n",
    "\n",
    "\n",
    "        # fid_update(reinhard_pred, reinhard_gt, reinhard_fid_metric)\n",
    "        # fid_update(pu_pred, pu_gt, pu_fid_metric)\n",
    "        \n",
    "    fvd_update(reinhard_preds, reinhard_gts, reinhard_fvd_metric)\n",
    "    fvd_update(pu_preds, pu_gts, pu_fvd_metric)\n",
    "\n",
    "# print(\"R-FID Score:\", compute_fid(reinhard_fid_metric))\n",
    "print(\"R-FVD Score:\", compute_fvd(reinhard_fvd_metric))\n",
    "# print(\"PU-FID Score:\", compute_fid(pu_fid_metric))\n",
    "print(\"PU-FVD Score:\", compute_fvd(pu_fvd_metric))\n",
    "\n",
    "print(\"Average PU-PSNR:\", np.mean(np.array(psnr_scores)))\n",
    "print(\"Average PU-VSI:\", np.mean(np.array(vsi_scores)))\n",
    "print(\"Average PIQE:\", np.mean(np.array(piqe_scores)))\n",
    "print(\"Average LPIPS:\", np.mean(np.array(lpips_scores)))\n",
    "\n",
    "    #add fid and fvd (then loop over videos, computer, save to csv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44990a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783aa022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
